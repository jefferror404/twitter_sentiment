# analysis/sentiment.py (Enhanced with Silent Mode)
"""
Enhanced sentiment analysis with silent mode for clean output
"""

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from .filters import TweetFilter
from .influence import InfluenceCalculator
from .topics import TopicAnalyzer
from api.coinex_api import CoinExAPI
from utils.tweet_parser import TweetParser
from utils.formatters import ReportFormatter
from config import ANALYSIS_CONFIG


class CryptoSentimentAnalyzer:
    def __init__(self, openai_api_key=None, silent_mode=False):
        self.openai_client = OpenAI(api_key=openai_api_key) if openai_api_key and OPENAI_AVAILABLE else None
        self.total_tokens_used = 0
        self.price_context = None
        self.silent_mode = silent_mode
        
        # Initialize components
        self.tweet_filter = TweetFilter(openai_api_key, silent_mode=silent_mode)
        self.influence_calculator = InfluenceCalculator()
        self.topic_analyzer = TopicAnalyzer(openai_api_key)
        self.coinex_api = CoinExAPI()
        self.tweet_parser = TweetParser()
        self.report_formatter = ReportFormatter()
    
    def analyze_sentiment_and_topic_combined(self, text):
        """Combined sentiment and topic analysis with price context awareness"""
        if not self.openai_client:
            return None
        
        try:
            # Build price context string if available
            price_context_str = ""
            if self.price_context:
                price_change = self.price_context['change_rate']
                price_direction = "ä¸Šæ¶¨" if price_change > 0 else "ä¸‹è·Œ" if price_change < 0 else "å¹³ç¨³"
                abs_change = abs(price_change)
                
                # Determine price movement significance
                if abs_change > 0.1:
                    movement_desc = "å‰§çƒˆæ³¢åŠ¨"
                elif abs_change > 0.05:
                    movement_desc = "æ˜¾è‘—æ³¢åŠ¨"
                elif abs_change > 0.02:
                    movement_desc = "è½»å¾®æ³¢åŠ¨"
                else:
                    movement_desc = "åŸºæœ¬ç¨³å®š"
                
                price_context_str = f"""
MARKET CONTEXT: å½“å‰ä»£å¸ä»·æ ¼{movement_desc}ï¼Œ24å°æ—¶{price_direction} {price_change:.2%}

IMPORTANT - ä»·æ ¼æ„ŸçŸ¥æƒ…æ„Ÿåˆ†ææŒ‡å¼•:
- ä»·æ ¼ä¸Šæ¶¨æ—¶ ({price_change:.2%} > 0): ä¸­æ€§/æ¨¡ç³Šè¯„è®ºå¯èƒ½åå‘ç§¯æï¼Œå…´å¥‹æƒ…ç»ªå¯èƒ½è¢«æ”¾å¤§
- ä»·æ ¼ä¸‹è·Œæ—¶ ({price_change:.2%} < 0): ä¸­æ€§/æ¨¡ç³Šè¯„è®ºå¯èƒ½åå‘æ¶ˆæï¼Œæ‹…å¿§æƒ…ç»ªå¯èƒ½è¢«åŠ å‰§
- ä»·æ ¼å¹³ç¨³æ—¶ (â‰ˆ0%): ä¸»è¦å…³æ³¨çº¯ç²¹æƒ…æ„Ÿï¼Œå‡å°‘ä»·æ ¼åè§
- å¼ºçƒˆä»·æ ¼æ³¢åŠ¨ (>5%): æ˜¾è‘—å½±å“æ¨æ–‡çš„æƒ…æ„ŸèƒŒæ™¯å’Œè§£è¯»
"""

            prompt = f"""
            Analyze this cryptocurrency tweet for BOTH sentiment and topic. Consider crypto slang, sarcasm, market context, and community dynamics.
            
            {price_context_str}
            
            Tweet: "{text}"
            
            SENTIMENT Guidelines:
            NEGATIVE: 
            Security issues (å®‰å…¨é—®é¢˜,é»‘å®¢,èµ„é‡‘è¢«ç›—,æ¼æ´,æ”»å‡»,æ¶æ„è½¯ä»¶), 
            Legal/Regulatory (ç ´äº§,æ‰§æ³•,ç›‘ç®¡,æ´—é’±,é£æ§,è¯ˆéª—), 
            Market risks (ä¸‹æ¶,çªå‘,é£é™©æç¤º,äº¤æ˜“æ‰€ST,äº¤æ˜“æ‰€å……æ), 
            Technical issues (ä»£å¹£å¢ç™¼,ä»£å¹£é‡‹æ”¾,ä»£å¹£è§£é–,è·¨é“¾æ¡¥,åœè©¦ç‡Ÿé‹), 
            General negative (dump,crash,scam,fraud,rug pull)
            
            POSITIVE: 
            General positive (moon,pump,bullish,gem,ä¸Šå¹£,ä¸Šæ‰€,ç©ºæŠ•), 
            Product Development (äº§å“å¼€å‘,äº§å“å‘å¸ƒ,åˆçº¦å‡çº§)
            
            NEUTRAL: Factual reporting, 
            Technical updates (ç¡¬åˆ†å‰,è¿ç§»,æ¢å¸,ä»£å¸ç»æµå­¦å˜æ›´)
            
            TOPIC Categories - Choose the MOST SPECIFIC sub-topic:
            
            ğŸ†• SPECIFIC TOPIC EXAMPLES:
            Technology: æ™ºèƒ½åˆçº¦æ¼æ´, è·¨é“¾æ¡¥é£é™©, å…±è¯†æœºåˆ¶å‡çº§, DeFiåè®®é£é™©, é’±åŒ…å®‰å…¨
            Market: å¤§æˆ·æŠ›å”®, æœºæ„ä¹°å…¥, äº¤æ˜“æ‰€ä¸Šæ¶, åšå¸‚å•†æ“æ§, æµåŠ¨æ€§å±æœº
            Community: CEOç¦»èŒ, å›¢é˜Ÿè§£æ•£, ç¤¾åŒºåˆ†æ­§, å¼€å‘åœæ», è·¯çº¿å›¾å»¶æœŸ
            Regulation: SECè°ƒæŸ¥, ç›‘ç®¡æ”¿ç­–, åˆè§„é—®é¢˜, æ³•å¾‹è¯‰è®¼, æ”¿åºœç¦ä»¤
            Price: çªç ´æ”¯æ’‘ä½, è·Œç ´é˜»åŠ›ä½, æŠ€æœ¯æŒ‡æ ‡çœ‹æ¶¨, æˆäº¤é‡èç¼©, ä»·æ ¼æ“æ§
            Partnerships: ä¸å¤§å‚åˆä½œ, æŠ•èµ„æœºæ„å…¥è‚¡, æˆ˜ç•¥è”ç›Ÿ, ç”Ÿæ€æ‰©å±•, æŠ€æœ¯æ•´åˆ
            
            IMPORTANT: 
            - Be VERY SPECIFIC about what exactly the concern/excitement is about
            - Instead of "æŠ€æœ¯é£é™©" use "æ™ºèƒ½åˆçº¦æ¼æ´" or "è·¨é“¾æ¡¥é£é™©"
            - Instead of "ç¤¾åŒºæ‹…å¿§" use "CEOç¦»èŒ" or "å¼€å‘åœæ»"  
            - Instead of "ç¤¾åŒºä¹è§‚" use "ä¸å¤§å‚åˆä½œ" or "ç”Ÿæ€æ‰©å±•"
            - Max 8 characters for topic name
            
            Respond EXACTLY in this format:
            SENTIMENT: [POSITIVE/NEGATIVE/NEUTRAL]
            CONFIDENCE: [0.0-1.0]
            TOPIC: [specific topic, max 8 chars]
            REASON: [One sentence explanation including price context influence if applicable]
            """
            
            response = self.openai_client.chat.completions.create(
                model=ANALYSIS_CONFIG['openai_model'],
                messages=[{"role": "user", "content": prompt}],
                max_completion_tokens=120,
                temperature=0.1
            )
            
            content = response.choices[0].message.content.strip()
            
            # Parse the structured response
            lines = content.split('\n')
            sentiment = None
            confidence = 0.5
            topic = "æœªåˆ†ç±»"
            reason = ""
            
            for line in lines:
                line = line.strip()
                if line.startswith('SENTIMENT:'):
                    sentiment = line.split(':', 1)[1].strip()
                elif line.startswith('CONFIDENCE:'):
                    try:
                        confidence = float(line.split(':', 1)[1].strip())
                    except:
                        confidence = 0.5
                elif line.startswith('TOPIC:'):
                    topic = line.split(':', 1)[1].strip()
                    # Clean up topic
                    if topic.startswith('- '):
                        topic = topic[2:].strip()
                    if topic.startswith('-'):
                        topic = topic[1:].strip()
                elif line.startswith('REASON:'):
                    reason = line.split(':', 1)[1].strip()
            
            # Fallback parsing if structured format fails
            if not sentiment:
                content_upper = content.upper()
                if 'NEGATIVE' in content_upper:
                    sentiment = 'NEGATIVE'
                elif 'POSITIVE' in content_upper:
                    sentiment = 'POSITIVE'
                else:
                    sentiment = 'NEUTRAL'
            
            # Track token usage
            if hasattr(response, 'usage'):
                self.total_tokens_used += response.usage.total_tokens
            
            return {
                'sentiment': sentiment,
                'confidence': confidence,
                'topic': topic,
                'reasoning': reason,
                'raw_response': content,
                'price_aware': bool(self.price_context)
            }
            
        except Exception as e:
            return None
    
    def analyze_tweet_sentiment(self, text):
        """Price-aware sentiment analysis using combined function"""
        combined_result = self.analyze_sentiment_and_topic_combined(text)
        
        if not combined_result:
            # Fallback if OpenAI fails
            return {
                'sentiment': 'NEUTRAL',
                'sentiment_score': 0,
                'confidence': 0.5,
                'topic': 'æœªåˆ†ç±»',
                'openai_analysis': None,
                'analysis_method': 'fallback_neutral',
                'price_influenced': False
            }
        
        # Convert sentiment to sentiment_score for compatibility
        sentiment_score = 0
        if combined_result['sentiment'] == 'POSITIVE':
            sentiment_score = 1
        elif combined_result['sentiment'] == 'NEGATIVE':
            sentiment_score = -1
        
        return {
            'sentiment': combined_result['sentiment'],
            'sentiment_score': sentiment_score,
            'confidence': combined_result['confidence'],
            'topic': combined_result['topic'],
            'openai_analysis': combined_result,
            'analysis_method': 'price_aware_combined',
            'price_influenced': combined_result.get('price_aware', False)
        }
    
    def generate_openai_summary(self, tweets_sample, token_symbol):
        """Generate OpenAI summary of tweets in Simplified Chinese with price context"""
        if not self.openai_client:
            return "OpenAIä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆæ™ºèƒ½æ‘˜è¦"
        
        try:
            max_tweets = ANALYSIS_CONFIG['max_tweets_for_summary']
            sample_tweets = tweets_sample[:max_tweets] if len(tweets_sample) > max_tweets else tweets_sample
            tweets_text = "\n".join([f"- {tweet['text'][:120]}..." if len(tweet['text']) > 120 else f"- {tweet['text']}" 
                                   for tweet in sample_tweets])
            
            # Add price context to summary if available
            price_context_str = ""
            if self.price_context:
                price_change = self.price_context['change_rate']
                price_usd = self.price_context['price_usd']
                price_context_str = f"""
å½“å‰å¸‚åœºçŠ¶å†µ: {token_symbol} ä»·æ ¼ ${price_usd:.6f} (24H: {price_change:+.2%})
è¯·åœ¨åˆ†æä¸­è€ƒè™‘ä»·æ ¼æ³¢åŠ¨å¯¹ç¤¾åŒºæƒ…ç»ªçš„å½±å“ã€‚
"""
            
            prompt = f"""
            è¯·åˆ†æè¿™{len(tweets_sample)}æ¡å…³äº{token_symbol}çš„æ¨æ–‡ï¼Œå¹¶æä¾›ç»¼åˆæ‘˜è¦ã€‚è¯·ç”¨ç®€ä½“ä¸­æ–‡å›å¤ã€‚
            
            {price_context_str}
            
            æ¨æ–‡æ ·æœ¬:
            {tweets_text}
            
            è¯·æä¾›åŒ…å«ä»¥ä¸‹å†…å®¹çš„æ‘˜è¦(ä»¥ä¸‹é¢çš„point formå½¢å¼æ˜¾ç¤º):
            1. æ•´ä½“æƒ…ç»ªå’Œç¤¾åŒºæ°›å›´ åŒ…å«è®¨è®ºçš„ä¸»è¦è¯é¢˜å’Œçƒ­ç‚¹ï¼‰
            2. ä¸»è¦æ‹…å¿§æˆ–å…´å¥‹ç‚¹ï¼ˆåŒ…å«è®¨è®ºçš„ä¸»è¦è¯é¢˜å’Œçƒ­ç‚¹ï¼‰
            3. æåŠçš„é£é™©å› ç´ ï¼ˆåŒ…å«æŠ€æœ¯ã€å¸‚åœºã€ç›‘ç®¡ç­‰å…·ä½“é£é™©ç±»å‹ï¼‰
            
            è¯·ä¿æŒç®€æ´ä½†æœ‰æ·±åº¦çš„åˆ†æ(æœ€å¤š3-4å¥è¯)ã€‚é‡ç‚¹å…³æ³¨å¯¹æŠ•èµ„è€…æœ‰ç”¨çš„è§è§£ã€‚
            è¯·åŠ¡å¿…ç”¨ç®€ä½“ä¸­æ–‡å›å¤ã€‚
            """
            
            response = self.openai_client.chat.completions.create(
                model=ANALYSIS_CONFIG['openai_model'],
                messages=[{"role": "user", "content": prompt}],
                max_completion_tokens=300,
                temperature=0.3
            )
            
            # Track token usage
            if hasattr(response, 'usage'):
                self.total_tokens_used += response.usage.total_tokens
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"OpenAIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}"
    
    def comprehensive_analysis(self, tweets, token_symbol):
        """Perform comprehensive price-aware sentiment analysis with enhanced filtering"""
        print(f"\n{'='*80}")
        print(f"ğŸš€ ä»·æ ¼æ„ŸçŸ¥æƒ…æ„Ÿåˆ†æ: {token_symbol}")
        print(f"{'='*80}")
        print(f"ğŸ“Š åŸå§‹æ¨æ–‡æ•°é‡: {len(tweets)}")
        
        # Step 1: Get price data from CoinEx API
        print(f"ğŸ’° è·å– {token_symbol} ä»·æ ¼æ•°æ®...")
        self.price_context = self.coinex_api.get_price_context(token_symbol)
        price_success = self.price_context is not None
        
        # Step 2: Enhanced filtering with team accounts
        filtered_tweets, exclusion_reasons = self.tweet_filter.filter_tweets(
            tweets, self.tweet_parser.parse_tweet_data, token_symbol
        )
        
        if not filtered_tweets:
            print("âŒ è¿‡æ»¤åæ— å¯åˆ†ææ¨æ–‡")
            return None
        
        if price_success:
            print(f"ğŸ“ˆ å¼€å§‹ä»·æ ¼æ„ŸçŸ¥åˆ†æ {len(filtered_tweets)} æ¡æœ‰æ•ˆæ¨æ–‡...")
        else:
            print(f"ğŸ“ˆ å¼€å§‹æ ‡å‡†åˆ†æ {len(filtered_tweets)} æ¡æœ‰æ•ˆæ¨æ–‡...")
        
        # First, do bulk topic analysis once with enhanced categorization
        tweets_for_topic_analysis = []
        for tweet in filtered_tweets:
            parsed = self.tweet_parser.parse_tweet_data(tweet)
            tweets_for_topic_analysis.append({'text': parsed['text']})
        
        self.topic_analyzer.generate_bulk_topic_analysis_with_sentiment(tweets_for_topic_analysis, token_symbol)
        
        tweet_analyses = []
        sentiment_summary = {'POSITIVE': 0, 'NEGATIVE': 0, 'NEUTRAL': 0}
        total_weighted_impact = 0
        high_influence_tweets = []
        viral_tweets = []
        price_influenced_count = 0
        
        for i, tweet in enumerate(filtered_tweets):
            try:
                parsed_tweet = self.tweet_parser.parse_tweet_data(tweet)
                
                # Use price-aware sentiment analysis
                sentiment_result = self.analyze_tweet_sentiment(parsed_tweet['text'])
                influence_data = self.influence_calculator.calculate_influence_score(parsed_tweet['user'])
                viral_data = self.influence_calculator.calculate_viral_index(parsed_tweet['metrics'])
                
                impact_data = self.influence_calculator.calculate_weighted_sentiment_impact(
                    sentiment_result, 
                    influence_data['influence_score'], 
                    viral_data['viral_index']
                )
                
                sentiment_summary[sentiment_result['sentiment']] += 1
                total_weighted_impact += impact_data['weighted_impact']
                
                # Count price-influenced analyses
                if sentiment_result.get('price_influenced', False):
                    price_influenced_count += 1
                
                # Get topic with sentiment from the combined analysis
                tweet_topic = self.topic_analyzer.get_tweet_topic_with_sentiment(
                    parsed_tweet['text'], 
                    sentiment_result.get('openai_analysis')
                )
                
                tweet_analysis = {
                    'tweet_num': i + 1,
                    'tweet_id': parsed_tweet['tweet_id'],
                    'user': parsed_tweet['user']['username'],
                    'text_preview': parsed_tweet['text'][:150] + '...' if len(parsed_tweet['text']) > 150 else parsed_tweet['text'],
                    'sentiment': sentiment_result,
                    'topic': tweet_topic,
                    'influence': influence_data,
                    'viral': viral_data,
                    'weighted_impact': impact_data,
                    'engagement': parsed_tweet['metrics']
                }
                
                tweet_analyses.append(tweet_analysis)
                
                if influence_data['influence_score'] >= 1.0:
                    high_influence_tweets.append(tweet_analysis)
                
                if viral_data['viral_index'] >= 5.0:
                    viral_tweets.append(tweet_analysis)
                    
            except Exception as e:
                print(f"Error analyzing tweet {i+1}: {e}")
                continue
        
        # Analyze topic sentiment distribution
        topic_sentiment_analysis = self.topic_analyzer.analyze_topic_sentiment_distribution(tweet_analyses)
        
        # Consolidate token usage from all components
        self.total_tokens_used += self.tweet_filter.total_tokens_used
        self.total_tokens_used += self.topic_analyzer.total_tokens_used
        
        # Get team filter stats
        team_filter_stats = self.tweet_filter.get_team_filter_stats()
        
        # Create enhanced result with team filtering info
        result = {
            'tweet_analyses': tweet_analyses,
            'sentiment_summary': sentiment_summary,
            'total_weighted_impact': total_weighted_impact,
            'high_influence_tweets': high_influence_tweets,
            'viral_tweets': viral_tweets,
            'filtering_stats': self.tweet_filter.filtered_counts,
            'team_filter_stats': team_filter_stats,
            'price_aware_stats': {
                'price_data_available': price_success,
                'price_influenced_count': price_influenced_count,
                'price_influence_rate': price_influenced_count / len(tweet_analyses) if tweet_analyses else 0,
                'price_context': self.price_context
            },
            'exclusion_reasons': exclusion_reasons,
            'bulk_topics': self.topic_analyzer.bulk_topics,
            'topic_sentiment_analysis': topic_sentiment_analysis,
            'total_tokens_used': self.total_tokens_used
        }
        
        # Generate and print the enhanced report
        self.report_formatter.print_enhanced_report(
            token_symbol, len(filtered_tweets), sentiment_summary, total_weighted_impact,
            high_influence_tweets, viral_tweets, tweet_analyses, tweets, result,
            self.generate_openai_summary, tweets_for_topic_analysis
        )
        
        return result

    def comprehensive_analysis_silent(self, tweets, token_symbol, target_days):
        """ğŸ†• Silent version of comprehensive analysis with clean output"""
        # Step 1: Get price data (silent)
        self.price_context = self.coinex_api.get_price_context_silent(token_symbol)
        price_success = self.price_context is not None
        
        # Step 2: Filter tweets (silent) - Use the existing silent TweetFilter
        filtered_tweets, exclusion_reasons = self.tweet_filter.filter_tweets_silent(
            tweets, self.tweet_parser.parse_tweet_data, token_symbol
        )
        
        if not filtered_tweets:
            # ğŸ†• Handle case where no tweets remain after filtering
            return None
        
        # Step 3: Topic analysis (silent)
        tweets_for_topic_analysis = []
        for tweet in filtered_tweets:
            parsed = self.tweet_parser.parse_tweet_data(tweet)
            tweets_for_topic_analysis.append({'text': parsed['text']})
        
        self.topic_analyzer.generate_bulk_topic_analysis_with_sentiment(tweets_for_topic_analysis, token_symbol)
        
        # Step 4: Analyze tweets (silent)
        tweet_analyses = []
        sentiment_summary = {'POSITIVE': 0, 'NEGATIVE': 0, 'NEUTRAL': 0}
        total_weighted_impact = 0
        high_influence_tweets = []
        viral_tweets = []
        price_influenced_count = 0
        
        for i, tweet in enumerate(filtered_tweets):
            try:
                parsed_tweet = self.tweet_parser.parse_tweet_data(tweet)
                
                sentiment_result = self.analyze_tweet_sentiment(parsed_tweet['text'])
                influence_data = self.influence_calculator.calculate_influence_score(parsed_tweet['user'])
                viral_data = self.influence_calculator.calculate_viral_index(parsed_tweet['metrics'])
                
                impact_data = self.influence_calculator.calculate_weighted_sentiment_impact(
                    sentiment_result, 
                    influence_data['influence_score'], 
                    viral_data['viral_index']
                )
                
                sentiment_summary[sentiment_result['sentiment']] += 1
                total_weighted_impact += impact_data['weighted_impact']
                
                if sentiment_result.get('price_influenced', False):
                    price_influenced_count += 1
                
                tweet_topic = self.topic_analyzer.get_tweet_topic_with_sentiment(
                    parsed_tweet['text'], 
                    sentiment_result.get('openai_analysis')
                )
                
                tweet_analysis = {
                    'tweet_num': i + 1,
                    'tweet_id': parsed_tweet['tweet_id'],
                    'user': parsed_tweet['user']['username'],
                    'text_preview': parsed_tweet['text'][:150] + '...' if len(parsed_tweet['text']) > 150 else parsed_tweet['text'],
                    'sentiment': sentiment_result,
                    'topic': tweet_topic,
                    'influence': influence_data,
                    'viral': viral_data,
                    'weighted_impact': impact_data,
                    'engagement': parsed_tweet['metrics']
                }
                
                tweet_analyses.append(tweet_analysis)
                
                if influence_data['influence_score'] >= 1.0:
                    high_influence_tweets.append(tweet_analysis)
                
                if viral_data['viral_index'] >= 5.0:
                    viral_tweets.append(tweet_analysis)
                    
            except Exception:
                continue
        
        # Consolidate stats
        topic_sentiment_analysis = self.topic_analyzer.analyze_topic_sentiment_distribution(tweet_analyses)
        self.total_tokens_used += self.tweet_filter.total_tokens_used
        self.total_tokens_used += self.topic_analyzer.total_tokens_used
        team_filter_stats = self.tweet_filter.get_team_filter_stats()
        
        # Create result
        result = {
            'tweet_analyses': tweet_analyses,
            'sentiment_summary': sentiment_summary,
            'total_weighted_impact': total_weighted_impact,
            'high_influence_tweets': high_influence_tweets,
            'viral_tweets': viral_tweets,
            'filtering_stats': self.tweet_filter.filtered_counts,
            'team_filter_stats': team_filter_stats,
            'price_aware_stats': {
                'price_data_available': price_success,
                'price_influenced_count': price_influenced_count,
                'price_influence_rate': price_influenced_count / len(tweet_analyses) if tweet_analyses else 0,
                'price_context': self.price_context
            },
            'exclusion_reasons': exclusion_reasons,
            'bulk_topics': self.topic_analyzer.bulk_topics,
            'topic_sentiment_analysis': topic_sentiment_analysis,
            'total_tokens_used': self.total_tokens_used
        }
        
        # ğŸ†• Generate clean, simplified report
        self.report_formatter.print_clean_report(
            token_symbol, len(tweets), len(filtered_tweets), sentiment_summary, 
            high_influence_tweets, viral_tweets, tweet_analyses, tweets, result,
            self.generate_openai_summary, tweets_for_topic_analysis, target_days
        )
        
        return result
