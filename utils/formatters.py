# utils/formatters.py (Enhanced with Clean Output)
"""
Enhanced output formatting with clean simplified output
"""

from .tweet_parser import TweetParser


class ReportFormatter:
    def __init__(self):
        self.tweet_parser = TweetParser()
    
    def print_table_header(self, columns, widths):
        """Helper function to print table headers"""
        header = "   "
        separator = "   "
        for i, (col, width) in enumerate(zip(columns, widths)):
            header += f"{col:<{width}}"
            separator += "-" * width
            if i < len(columns) - 1:
                header += " | "
                separator += "-|-"
        print(header)
        print(separator)

    def print_table_row(self, values, widths):
        """Helper function to print table rows"""
        row = "   "
        for i, (val, width) in enumerate(zip(values, widths)):
            val_str = str(val)
            if len(val_str) > width:
                val_str = val_str[:width-3] + "..."
            row += f"{val_str:<{width}}"
            if i < len(values) - 1:
                row += " | "
        print(row)

    def print_clean_report(self, token, total_tweets, effective_tweets, sentiment_summary, 
                          high_influence_tweets, viral_tweets, tweet_analyses, original_tweets, result,
                          generate_summary_func, tweets_for_summary, target_days):
        """ğŸ†• Clean, simplified report format"""
        
        # ğŸ†• Updated header format
        print(f'ğŸ” "{token}" è¿‘{target_days}å¤©æ¨æ–‡æƒ…æ„Ÿåˆ†æ')
        print(f"åŸè·å–æ¨æ–‡æ•°é‡: {total_tweets}; è¿‡æ»¤åæœ‰æ•ˆæ¨æ–‡: {effective_tweets}")
        
        # Price data overview
        price_stats = result.get('price_aware_stats', {})
        if price_stats.get('price_data_available') and price_stats.get('price_context'):
            price_data = price_stats['price_context']
            print(f"ğŸ’° ç«™å†…æ•°æ®æ€»è§ˆ:")  # ğŸ†• Updated label
            print(f"   ğŸ’µ å½“å‰ä»·æ ¼: ${price_data['price_usd']:.6f}")
            print(f"   ğŸ“ˆ 24Hå˜åŒ–: {price_data['change_rate']:+.2%}")
            print(f"   ğŸ’§ 24Häº¤æ˜“é‡: ${price_data['volume_usd']:,.0f}")
        else:
            print("ğŸ’° ç«™å†…æ•°æ®æ€»è§ˆ:")  # ğŸ†• Updated label
            print("   ğŸ’° ä»·æ ¼æ•°æ®: æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®")
        
        print()
        
        # Sentiment distribution (keep entirely)
        total = sum(sentiment_summary.values())
        pos_pct = (sentiment_summary['POSITIVE'] / total * 100) if total > 0 else 0
        neg_pct = (sentiment_summary['NEGATIVE'] / total * 100) if total > 0 else 0
        neu_pct = (sentiment_summary['NEUTRAL'] / total * 100) if total > 0 else 0
        
        print(f"ğŸ­ æƒ…ç»ªåˆ†å¸ƒ:")
        print(f"   âœ… æ­£é¢: {sentiment_summary['POSITIVE']} æ¡ ({pos_pct:.1f}%)")
        print(f"   âŒ è´Ÿé¢: {sentiment_summary['NEGATIVE']} æ¡ ({neg_pct:.1f}%)")
        print(f"   âšª ä¸­æ€§: {sentiment_summary['NEUTRAL']} æ¡ ({neu_pct:.1f}%)")
        
        # ğŸ†• Remove AI analysis success rate lines
        # No longer showing:
        # - AIåˆ†ææˆåŠŸ
        # - ä»·æ ¼æ„ŸçŸ¥åˆ†æ
        
        # AI summary (keep entirely)
        print(f"\nğŸ¤– AI æ™ºèƒ½åˆ†ææ‘˜è¦:")
        print("   " + "="*50)
        try:
            ai_summary = generate_summary_func(tweets_for_summary, token)
            summary_lines = ai_summary.split('\n')
            for line in summary_lines:
                if line.strip():
                    print(f"   {line}")
            print("   " + "="*50)
        except Exception as e:
            print(f"   AIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
        
        # ğŸ†• Simplified Topic analysis (remove sentiment breakdown)
        print(f"\nğŸ“ˆ çƒ­é—¨è¯é¢˜æ¦œ:")
        bulk_topics = result.get('bulk_topics', [])
        
        if bulk_topics:
            print("   AIæ™ºèƒ½è¯é¢˜åˆ†æ:")
            for i, topic in enumerate(bulk_topics[:6]):
                bar = 'â–ˆ' * min(int(topic['count']/2), 8) + 'â–' * max(0, 8 - int(topic['count']/2))
                # ğŸ†• Remove the [ä¸»è¦:ç§¯æ 20/6] part
                print(f"   {i+1:2d}. {topic['name']:<15} {bar} ({topic['count']}æ¡)")
        else:
            print("   æš‚æ— è¯é¢˜åˆ†æç»“æœ")
        
        # High influence tweets and viral tweets (keep entirely)
        print(f"\nğŸ”¥ ç—…æ¯’å¼ä¼ æ’­æ¨æ–‡ (ä¼ æ’­åŠ›â‰¥5.0):")
        if viral_tweets:
            sorted_viral = sorted(viral_tweets, key=lambda x: x['viral']['viral_index'], reverse=True)[:6]
            
            # ğŸ†• Increased width for topic column
            columns = ["ç”¨æˆ·å", "ä¼ æ’­åŠ›", "ç‚¹èµ", "è½¬æ¨", "å›å¤", "æƒ…ç»ª", "è¯é¢˜", "æ¨æ–‡é“¾æ¥"]
            widths = [12, 8, 8, 8, 8, 8, 25, 45]  # Increased topic width from 18 to 25
            
            self.print_table_header(columns, widths)
            
            for tweet in sorted_viral:
                engagement = tweet['engagement']
                tweet_topic = tweet.get('topic', 'æœªåˆ†ç±»')
                
                original_tweet = None
                for orig_tweet in original_tweets:
                    parsed_orig = self.tweet_parser.parse_tweet_data(orig_tweet)
                    if parsed_orig['tweet_id'] == tweet['tweet_id']:
                        original_tweet = orig_tweet
                        break
                
                full_tweet_id = self.tweet_parser.extract_tweet_id_for_link(original_tweet) if original_tweet else tweet['tweet_id']
                tweet_link = self.tweet_parser.create_tweet_link(full_tweet_id)
                
                values = [
                    f"@{tweet['user']}",
                    f"{tweet['viral']['viral_index']:.1f}",
                    f"{engagement['likes']:,}",
                    f"{engagement['retweets']:,}",
                    f"{engagement['replies']:,}",
                    tweet['sentiment']['sentiment'],
                    tweet_topic,  # ğŸ†• Full topic name without truncation
                    tweet_link
                ]
                self.print_table_row(values, widths)
        else:
            print("   æš‚æ— ç¬¦åˆæ¡ä»¶çš„ç—…æ¯’å¼ä¼ æ’­æ¨æ–‡")
        
        # High influence tweets
        print(f"\nğŸ‘‘ é«˜å½±å“åŠ›ç”¨æˆ·åŠ¨æ€ (å½±å“åŠ›â‰¥1.0):")
        if high_influence_tweets:
            sorted_influence = sorted(high_influence_tweets, key=lambda x: x['influence']['influence_score'], reverse=True)[:8]
            
            # ğŸ†• Increased width for topic column
            columns = ["ç”¨æˆ·å", "å½±å“åŠ›", "ç²‰ä¸æ•°", "æƒ…ç»ª", "ä¼ æ’­åŠ›", "è¯é¢˜", "æ¨æ–‡é“¾æ¥"]
            widths = [12, 8, 10, 8, 8, 25, 45]  # Increased topic width from 18 to 25
            
            self.print_table_header(columns, widths)
            
            for tweet in sorted_influence:
                followers = tweet['influence']['followers_tier'].split(': ')[1] if ': ' in tweet['influence']['followers_tier'] else str(tweet['user'])
                tweet_topic = tweet.get('topic', 'æœªåˆ†ç±»')
                
                original_tweet = None
                for orig_tweet in original_tweets:
                    parsed_orig = self.tweet_parser.parse_tweet_data(orig_tweet)
                    if parsed_orig['tweet_id'] == tweet['tweet_id']:
                        original_tweet = orig_tweet
                        break
                
                full_tweet_id = self.tweet_parser.extract_tweet_id_for_link(original_tweet) if original_tweet else tweet['tweet_id']
                tweet_link = self.tweet_parser.create_tweet_link(full_tweet_id)
                
                values = [
                    f"@{tweet['user']}",
                    f"{tweet['influence']['influence_score']:.1f}",
                    followers,
                    tweet['sentiment']['sentiment'],
                    f"{tweet['viral']['viral_index']:.1f}",
                    tweet_topic,  # ğŸ†• Full topic name without truncation
                    tweet_link
                ]
                self.print_table_row(values, widths)
        else:
            print("   æš‚æ— ç¬¦åˆæ¡ä»¶çš„é«˜å½±å“åŠ›ç”¨æˆ·æ¨æ–‡")

    def print_filtered_tweets_table(self, exclusion_reasons, original_tweets):
        """Print detailed table of filtered tweets with wider AI columns (keep logic but don't show)"""
        # Keep all the logic for internal processing but don't print anything
        # This maintains the functionality for debugging purposes if needed
        
        if not exclusion_reasons:
            return
        
        # Enhanced grouping with team accounts (logic preserved)
        filter_groups = {
            'æ–°é—»è´¦æˆ·': [],
            'å›¢é˜Ÿè´¦æˆ·': [],
            'åŸºç¡€åƒåœ¾': [],
            'AIåƒåœ¾': [],
            'AIä¿¡æ¯': []
        }
        
        for reason in exclusion_reasons:
            if "News account" in reason['reason']:
                filter_groups['æ–°é—»è´¦æˆ·'].append(reason)
            elif "Team account" in reason['reason']:
                filter_groups['å›¢é˜Ÿè´¦æˆ·'].append(reason)
            elif "Basic spam" in reason['reason']:
                filter_groups['åŸºç¡€åƒåœ¾'].append(reason)
            elif "AI spam" in reason['reason']:
                filter_groups['AIåƒåœ¾'].append(reason)
            elif "AI informative" in reason['reason']:
                filter_groups['AIä¿¡æ¯'].append(reason)
        
        # Logic is preserved but output is suppressed
        # This can be re-enabled for debugging by uncommenting the print statements below
        
        """
        print(f"\nğŸ” å·²è¿‡æ»¤æ¨æ–‡è¯¦æƒ…è¡¨ (å…± {len(exclusion_reasons)} æ¡):")
        print("=" * 140)
        
        # Print each group
        for filter_type, filtered_tweets in filter_groups.items():
            if not filtered_tweets:
                continue
                
            print(f"\nğŸ“‹ {filter_type} è¿‡æ»¤ ({len(filtered_tweets)} æ¡):")
            
            if filter_type in ['æ–°é—»è´¦æˆ·', 'å›¢é˜Ÿè´¦æˆ·', 'åŸºç¡€åƒåœ¾']:
                columns = ["#", "ç”¨æˆ·å", "ç²‰ä¸æ•°", "æ¨æ–‡é¢„è§ˆ", "æ¨æ–‡é“¾æ¥"]
                widths = [3, 15, 8, 35, 45]
            else:
                columns = ["#", "ç”¨æˆ·å", "AIåˆ¤æ–­", "æ¨æ–‡é¢„è§ˆ", "æ¨æ–‡é“¾æ¥"]
                widths = [3, 15, 20, 30, 45]
            
            self.print_table_header(columns, widths)
            
            for reason in filtered_tweets:
                # Find the original tweet to get the full ID
                original_tweet = None
                for orig_tweet in original_tweets:
                    try:
                        parsed_orig = self.tweet_parser.parse_tweet_data(orig_tweet)
                        if (parsed_orig['user']['username'] == reason['user'] and 
                            reason['full_text'][:50] in parsed_orig['text']):
                            original_tweet = orig_tweet
                            break
                    except:
                        continue
                
                full_tweet_id = self.tweet_parser.extract_tweet_id_for_link(original_tweet) if original_tweet else "N/A"
                tweet_link = self.tweet_parser.create_tweet_link(full_tweet_id)
                
                text_preview = reason['text_preview']
                max_preview_len = 35 if filter_type in ['æ–°é—»è´¦æˆ·', 'å›¢é˜Ÿè´¦æˆ·', 'åŸºç¡€åƒåœ¾'] else 30
                if len(text_preview) > max_preview_len:
                    text_preview = text_preview[:max_preview_len-3] + "..."
                
                if filter_type in ['æ–°é—»è´¦æˆ·', 'å›¢é˜Ÿè´¦æˆ·', 'åŸºç¡€åƒåœ¾']:
                    values = [
                        str(reason['tweet_num']),
                        f"@{reason['user']}",
                        f"{reason['followers']:,}",
                        text_preview,
                        tweet_link
                    ]
                else:
                    ai_reason = reason['detailed_reason']
                    if len(ai_reason) > 20:
                        ai_reason = ai_reason[:17] + "..."
                    
                    values = [
                        str(reason['tweet_num']),
                        f"@{reason['user']}",
                        ai_reason,
                        text_preview,
                        tweet_link
                    ]
                
                self.print_table_row(values, widths)
        
        print(f"\nğŸ’¡ éªŒè¯æç¤º: ç‚¹å‡»æ¨æ–‡é“¾æ¥å¯æŸ¥çœ‹å®Œæ•´å†…å®¹ï¼ŒéªŒè¯è¿‡æ»¤å‡†ç¡®æ€§")
        print("=" * 140)
        """

    def print_enhanced_report(self, token, tweet_count, sentiment_summary, total_weighted_impact,
                             high_influence_tweets, viral_tweets, tweet_analyses, original_tweets, result,
                             generate_summary_func, tweets_for_summary):
        """Enhanced report with team filtering statistics (original verbose version for debugging)"""
        
        print(f"\nğŸ“‹ {token} ä»·æ ¼æ„ŸçŸ¥æƒ…ç»ªåˆ†ææŠ¥å‘Š")
        print("=" * 80)
        
        # Price awareness summary
        price_stats = result.get('price_aware_stats', {})
        if price_stats.get('price_data_available') and price_stats.get('price_context'):
            price_data = price_stats['price_context']
            print(f"ğŸ’° ä»·æ ¼æ•°æ®æ€»è§ˆ:")
            print(f"   ğŸ’µ å½“å‰ä»·æ ¼: ${price_data['price_usd']:.6f}")
            print(f"   ğŸ“ˆ 24Hå˜åŒ–: {price_data['change_rate']:+.2%}")
            print(f"   ğŸ’§ 24Häº¤æ˜“é‡: ${price_data['volume_usd']:,.0f}")
            print(f"   ğŸ¯ ä»·æ ¼å½±å“åˆ†æ: {price_stats['price_influenced_count']}/{len(tweet_analyses)} æ¡ ({price_stats['price_influence_rate']*100:.1f}%)")
            
            # Price impact description
            abs_change = abs(price_data['change_rate'])
            if abs_change > 0.1:
                print(f"   âš¡ ä»·æ ¼å‰§çƒˆæ³¢åŠ¨å¯¹æƒ…æ„Ÿåˆ†æäº§ç”Ÿæ˜¾è‘—å½±å“")
            elif abs_change > 0.05:
                print(f"   ğŸ“Š ä»·æ ¼æ˜æ˜¾æ³¢åŠ¨é€‚åº¦å½±å“æƒ…æ„Ÿè§£è¯»")
            else:
                print(f"   ğŸ˜ ä»·æ ¼ç›¸å¯¹ç¨³å®šï¼Œä¸»è¦åŸºäºåŸå§‹æƒ…æ„Ÿ")
        else:
            print(f"ğŸ’° ä»·æ ¼æ•°æ®: æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨æ ‡å‡†æƒ…æ„Ÿåˆ†æ")
        
        print()
        
        # Enhanced filtering summary with team filtering
        filtering_stats = result.get('filtering_stats', {})
        team_filter_stats = result.get('team_filter_stats', {})
        
        print(f"ğŸ” æ•°æ®è´¨é‡ç»Ÿè®¡:")
        print(f"   ğŸ“¥ åŸå§‹æ¨æ–‡: {tweet_count + filtering_stats.get('total_filtered', 0)} æ¡")
        print(f"   ğŸ—ï¸  æ–°é—»è¿‡æ»¤: {filtering_stats.get('news_accounts', 0)} æ¡")
        
        # Show team filtering if enabled
        if team_filter_stats.get('enabled', False):
            team_filtered = filtering_stats.get('team_accounts', 0)
            print(f"   ğŸ‘¥ å›¢é˜Ÿè¿‡æ»¤: {team_filtered} æ¡")
            if team_filter_stats.get('is_loaded', False):
                print(f"      ğŸ“Š å›¢é˜Ÿæ•°æ®åº“: {team_filter_stats.get('total_projects', 0)} ä¸ªé¡¹ç›®")
        
        print(f"   ğŸš« åƒåœ¾è¿‡æ»¤: {filtering_stats.get('spam_basic', 0) + filtering_stats.get('spam_ai', 0)} æ¡")
        print(f"   ğŸ“° ä¿¡æ¯è¿‡æ»¤: {filtering_stats.get('informative_ai', 0)} æ¡")
        print(f"   âœ… æœ‰æ•ˆåˆ†æ: {tweet_count} æ¡ ({tweet_count/(tweet_count + filtering_stats.get('total_filtered', 0))*100:.1f}%)")
        print()
        
        total = sum(sentiment_summary.values())
        pos_pct = (sentiment_summary['POSITIVE'] / total * 100) if total > 0 else 0
        neg_pct = (sentiment_summary['NEGATIVE'] / total * 100) if total > 0 else 0
        neu_pct = (sentiment_summary['NEUTRAL'] / total * 100) if total > 0 else 0
        
        print(f"ğŸ­ æƒ…ç»ªåˆ†å¸ƒ:")
        print(f"   âœ… æ­£é¢: {sentiment_summary['POSITIVE']} æ¡ ({pos_pct:.1f}%)")
        print(f"   âŒ è´Ÿé¢: {sentiment_summary['NEGATIVE']} æ¡ ({neg_pct:.1f}%)")
        print(f"   âšª ä¸­æ€§: {sentiment_summary['NEUTRAL']} æ¡ ({neu_pct:.1f}%)")
        
        # Add analysis success rate
        openai_success = 0
        price_aware_success = 0
        for tweet in tweet_analyses:
            if tweet['sentiment']['openai_analysis']:
                openai_success += 1
            if tweet['sentiment'].get('price_influenced', False):
                price_aware_success += 1
        
        print(f"   ğŸ“Š AIåˆ†ææˆåŠŸ: {openai_success}/{len(tweet_analyses)} æ¡ ({openai_success/len(tweet_analyses)*100:.1f}%)")
        if price_stats.get('price_data_available'):
            print(f"   ğŸ’° ä»·æ ¼æ„ŸçŸ¥åˆ†æ: {price_aware_success}/{len(tweet_analyses)} æ¡ ({price_aware_success/len(tweet_analyses)*100:.1f}%)")
        
        # Add neutral tweets table with sentiment-aware topics
        neutral_tweets = [t for t in tweet_analyses if t['sentiment']['sentiment'] == 'NEUTRAL']
        if neutral_tweets and len(neutral_tweets) > 0:
            print(f"\nâšª ä¸­æ€§æƒ…ç»ªæ¨æ–‡è¯¦æƒ…:")
            
            columns = ["ç”¨æˆ·å", "è¯é¢˜", "ä»·æ ¼å½±å“", "æ¨æ–‡é“¾æ¥"]
            widths = [15, 20, 10, 45]
            
            self.print_table_header(columns, widths)
            
            for tweet in neutral_tweets[:8]:
                tweet_topic = tweet.get('topic', 'æœªåˆ†ç±»')
                price_influenced = "æ˜¯" if tweet['sentiment'].get('price_influenced', False) else "å¦"
                
                original_tweet = None
                for orig_tweet in original_tweets:
                    parsed_orig = self.tweet_parser.parse_tweet_data(orig_tweet)
                    if parsed_orig['tweet_id'] == tweet['tweet_id']:
                        original_tweet = orig_tweet
                        break
                
                full_tweet_id = self.tweet_parser.extract_tweet_id_for_link(original_tweet) if original_tweet else tweet['tweet_id']
                tweet_link = self.tweet_parser.create_tweet_link(full_tweet_id)
                
                values = [
                    f"@{tweet['user']}",
                    tweet_topic,
                    price_influenced,
                    tweet_link
                ]
                self.print_table_row(values, widths)
        
        print(f"\nğŸ¤– AI æ™ºèƒ½åˆ†ææ‘˜è¦:")
        print("   " + "="*50)
        try:
            ai_summary = generate_summary_func(tweets_for_summary, token)
            summary_lines = ai_summary.split('\n')
            for line in summary_lines:
                if line.strip():
                    print(f"   {line}")
            print("   " + "="*50)
        except Exception as e:
            print(f"   AIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
        
        # Enhanced Topic analysis with sentiment
        print(f"\nğŸ“ˆ çƒ­é—¨è¯é¢˜æ¦œ (å«æƒ…æ„Ÿæ–¹å‘):")
        bulk_topics = result.get('bulk_topics', [])
        topic_sentiment_analysis = result.get('topic_sentiment_analysis', {})
        
        if bulk_topics:
            print("   AIæ™ºèƒ½è¯é¢˜åˆ†æ:")
            for i, topic in enumerate(bulk_topics[:6]):
                bar = 'â–ˆ' * min(int(topic['count']/2), 8) + 'â–' * max(0, 8 - int(topic['count']/2))
                
                # Get sentiment distribution for this topic if available
                sentiment_info = ""
                if topic['name'] in topic_sentiment_analysis:
                    topic_stats = topic_sentiment_analysis[topic['name']]
                    pos_count = topic_stats.get('POSITIVE', 0)
                    neg_count = topic_stats.get('NEGATIVE', 0)
                    neu_count = topic_stats.get('NEUTRAL', 0)
                    
                    # Show dominant sentiment
                    if pos_count > neg_count and pos_count > neu_count:
                        sentiment_info = f" [ä¸»è¦:ç§¯æ {pos_count}/{topic['count']}]"
                    elif neg_count > pos_count and neg_count > neu_count:
                        sentiment_info = f" [ä¸»è¦:æ¶ˆæ {neg_count}/{topic['count']}]"
                    elif neu_count > 0:
                        sentiment_info = f" [ä¸»è¦:ä¸­æ€§ {neu_count}/{topic['count']}]"
                
                print(f"   {i+1:2d}. {topic['name']:<15} {bar} ({topic['count']}æ¡){sentiment_info}")
        else:
            print("   æš‚æ— è¯é¢˜åˆ†æç»“æœ")
        
        # Enhanced Viral tweets with sentiment-aware topics
        print(f"\nğŸ”¥ ç—…æ¯’å¼ä¼ æ’­æ¨æ–‡ (ä¼ æ’­åŠ›â‰¥5.0):")
        if viral_tweets:
            sorted_viral = sorted(viral_tweets, key=lambda x: x['viral']['viral_index'], reverse=True)[:6]
            
            columns = ["ç”¨æˆ·å", "ä¼ æ’­åŠ›", "ç‚¹èµ", "è½¬æ¨", "å›å¤", "æƒ…ç»ª", "è¯é¢˜", "æ¨æ–‡é“¾æ¥"]
            widths = [12, 8, 8, 8, 8, 8, 18, 45]
            
            self.print_table_header(columns, widths)
            
            for tweet in sorted_viral:
                engagement = tweet['engagement']
                tweet_topic = tweet.get('topic', 'æœªåˆ†ç±»')
                
                original_tweet = None
                for orig_tweet in original_tweets:
                    parsed_orig = self.tweet_parser.parse_tweet_data(orig_tweet)
                    if parsed_orig['tweet_id'] == tweet['tweet_id']:
                        original_tweet = orig_tweet
                        break
                
                full_tweet_id = self.tweet_parser.extract_tweet_id_for_link(original_tweet) if original_tweet else tweet['tweet_id']
                tweet_link = self.tweet_parser.create_tweet_link(full_tweet_id)
                
                values = [
                    f"@{tweet['user']}",
                    f"{tweet['viral']['viral_index']:.1f}",
                    f"{engagement['likes']:,}",
                    f"{engagement['retweets']:,}",
                    f"{engagement['replies']:,}",
                    tweet['sentiment']['sentiment'],
                    tweet_topic,
                    tweet_link
                ]
                self.print_table_row(values, widths)
        else:
            print("   æš‚æ— ç¬¦åˆæ¡ä»¶çš„ç—…æ¯’å¼ä¼ æ’­æ¨æ–‡")
        
        # Enhanced High influence tweets with sentiment-aware topics
        print(f"\nğŸ‘‘ é«˜å½±å“åŠ›ç”¨æˆ·åŠ¨æ€ (å½±å“åŠ›â‰¥1.0):")
        if high_influence_tweets:
            sorted_influence = sorted(high_influence_tweets, key=lambda x: x['influence']['influence_score'], reverse=True)[:8]
            
            columns = ["ç”¨æˆ·å", "å½±å“åŠ›", "ç²‰ä¸æ•°", "æƒ…ç»ª", "ä¼ æ’­åŠ›", "è¯é¢˜", "æ¨æ–‡é“¾æ¥"]
            widths = [12, 8, 10, 8, 8, 18, 45]
            
            self.print_table_header(columns, widths)
            
            for tweet in sorted_influence:
                followers = tweet['influence']['followers_tier'].split(': ')[1] if ': ' in tweet['influence']['followers_tier'] else str(tweet['user'])
                tweet_topic = tweet.get('topic', 'æœªåˆ†ç±»')
                
                original_tweet = None
                for orig_tweet in original_tweets:
                    parsed_orig = self.tweet_parser.parse_tweet_data(orig_tweet)
                    if parsed_orig['tweet_id'] == tweet['tweet_id']:
                        original_tweet = orig_tweet
                        break
                
                full_tweet_id = self.tweet_parser.extract_tweet_id_for_link(original_tweet) if original_tweet else tweet['tweet_id']
                tweet_link = self.tweet_parser.create_tweet_link(full_tweet_id)
                
                values = [
                    f"@{tweet['user']}",
                    f"{tweet['influence']['influence_score']:.1f}",
                    followers,
                    tweet['sentiment']['sentiment'],
                    f"{tweet['viral']['viral_index']:.1f}",
                    tweet_topic,
                    tweet_link
                ]
                self.print_table_row(values, widths)
        else:
            print("   æš‚æ— ç¬¦åˆæ¡ä»¶çš„é«˜å½±å“åŠ›ç”¨æˆ·æ¨æ–‡")
        
        # Show detailed filtered tweets table if available (keep logic but suppress output)
        exclusion_reasons = result.get('exclusion_reasons', [])
        if exclusion_reasons:
            self.print_filtered_tweets_table(exclusion_reasons, original_tweets)
        
        print(f"\n{'='*80}")
        
        # OpenAI token usage summary (commented out for clean output)
        """
        total_tokens_used = result.get('total_tokens_used', 0)
        if total_tokens_used > 0:
            estimated_cost = (total_tokens_used * 0.375) / 1000000
            
            print(f"ğŸ’° OpenAI APIä½¿ç”¨ç»Ÿè®¡:")
            print(f"   ğŸ”¢ æ€»Tokensæ¶ˆè€—: {total_tokens_used:,}")
            print(f"   ğŸ’µ é¢„ä¼°è´¹ç”¨: ${estimated_cost:.4f} USD")
            print(f"   ğŸ“ æ¨¡å‹: gpt-4o-mini")
            print(f"   ğŸ” è¿‡æ»¤è°ƒç”¨: ~{filtering_stats.get('spam_ai', 0) + filtering_stats.get('informative_ai', 0)} æ¬¡")
            print(f"   ğŸ“Š åˆ†æè°ƒç”¨: ~{len(tweet_analyses)} æ¬¡")
            if price_stats.get('price_data_available'):
                print(f"   ğŸ’° ä»·æ ¼æ„ŸçŸ¥å¢å¼º: {price_stats['price_influenced_count']} æ¡æ¨æ–‡")
            print(f"\n{'='*80}")
        """